[
    {
        "title": "On the Measure of Intelligence",
        "url": "http://arxiv.org/abs/1911.01547v2",
        "authors": [
            "Fran\u00e7ois Chollet"
        ],
        "abstract": "To make deliberate progress towards more intelligent and more human-like artificial systems, we need to be following an appropriate feedback signal: we need to be able to define and evaluate intelligence in a way that enables comparisons between two systems, as well as comparisons with humans. Over the past hundred years, there has been an abundance of attempts to define and measure intelligence, across both the fields of psychology and AI. We summarize and critically assess these definitions and evaluation approaches, while making apparent the two historical conceptions of intelligence that have implicitly guided them. We note that in practice, the contemporary AI community still gravitates towards benchmarking intelligence by comparing the skill exhibited by AIs and humans at specific tasks such as board games and video games. We argue that solely measuring skill at any given task falls short of measuring intelligence, because skill is heavily modulated by prior knowledge and experience: unlimited priors or unlimited training data allow experimenters to \"buy\" arbitrary levels of skills for a system, in a way that masks the system's own generalization power. We then articulate a new formal definition of intelligence based on Algorithmic Information Theory, describing intelligence as skill-acquisition efficiency and highlighting the concepts of scope, generalization difficulty, priors, and experience. Using this definition, we propose a set of guidelines for what a general AI benchmark should look like. Finally, we present a benchmark closely following these guidelines, the Abstraction and Reasoning Corpus (ARC), built upon an explicit set of priors designed to be as close as possible to innate human priors. We argue that ARC can be used to measure a human-like form of general fluid intelligence and that it enables fair general intelligence comparisons between AI systems and humans.",
        "file": "data/1911.01547.pdf"
    },
    {
        "title": "Lossy Image Compression with Normalizing Flows",
        "url": "http://arxiv.org/abs/2008.10486v1",
        "authors": [
            "Leonhard Helminger",
            "Abdelaziz Djelouah",
            "Markus Gross",
            "Christopher Schroers"
        ],
        "abstract": "Deep learning based image compression has recently witnessed exciting progress and in some cases even managed to surpass transform coding based approaches that have been established and refined over many decades. However, state-of-the-art solutions for deep image compression typically employ autoencoders which map the input to a lower dimensional latent space and thus irreversibly discard information already before quantization. Due to that, they inherently limit the range of quality levels that can be covered. In contrast, traditional approaches in image compression allow for a larger range of quality levels. Interestingly, they employ an invertible transformation before performing the quantization step which explicitly discards information. Inspired by this, we propose a deep image compression method that is able to go from low bit-rates to near lossless quality by leveraging normalizing flows to learn a bijective mapping from the image space to a latent representation. In addition to this, we demonstrate further advantages unique to our solution, such as the ability to maintain constant quality results through re-encoding, even when performed multiple times. To the best of our knowledge, this is the first work to explore the opportunities for leveraging normalizing flows for lossy image compression.",
        "file": "data/2008.10486.pdf"
    },
    {
        "title": "Unifying Approaches in Active Learning and Active Sampling via Fisher Information and Information-Theoretic Quantities",
        "url": "http://arxiv.org/abs/2208.00549v2",
        "authors": [
            "Andreas Kirsch",
            "Yarin Gal"
        ],
        "abstract": "Recently proposed methods in data subset selection, that is active learning and active sampling, use Fisher information, Hessians, similarity matrices based on gradients, and gradient lengths to estimate how informative data is for a model's training. Are these different approaches connected, and if so, how? We revisit the fundamentals of Bayesian optimal experiment design and show that these recently proposed methods can be understood as approximations to information-theoretic quantities: among them, the mutual information between predictions and model parameters, known as expected information gain or BALD in machine learning, and the mutual information between predictions of acquisition candidates and test samples, known as expected predictive information gain. We develop a comprehensive set of approximations using Fisher information and observed information and derive a unified framework that connects seemingly disparate literature. Although Bayesian methods are often seen as separate from non-Bayesian ones, the sometimes fuzzy notion of \"informativeness\" expressed in various non-Bayesian objectives leads to the same couple of information quantities, which were, in principle, already known by Lindley (1956) and MacKay (1992).",
        "file": "data/2208.00549.pdf"
    },
    {
        "title": "Maximum Entropy Weighted Independent Set Pooling for Graph Neural Networks",
        "url": "http://arxiv.org/abs/2107.01410v1",
        "authors": [
            "Amirhossein Nouranizadeh",
            "Mohammadjavad Matinkia",
            "Mohammad Rahmati",
            "Reza Safabakhsh"
        ],
        "abstract": "In this paper, we propose a novel pooling layer for graph neural networks based on maximizing the mutual information between the pooled graph and the input graph. Since the maximum mutual information is difficult to compute, we employ the Shannon capacity of a graph as an inductive bias to our pooling method. More precisely, we show that the input graph to the pooling layer can be viewed as a representation of a noisy communication channel. For such a channel, sending the symbols belonging to an independent set of the graph yields a reliable and error-free transmission of information. We show that reaching the maximum mutual information is equivalent to finding a maximum weight independent set of the graph where the weights convey entropy contents. Through this communication theoretic standpoint, we provide a distinct perspective for posing the problem of graph pooling as maximizing the information transmission rate across a noisy communication channel, implemented by a graph neural network. We evaluate our method, referred to as Maximum Entropy Weighted Independent Set Pooling (MEWISPool), on graph classification tasks and the combinatorial optimization problem of the maximum independent set. Empirical results demonstrate that our method achieves the state-of-the-art and competitive results on graph classification tasks and the maximum independent set problem in several benchmark datasets.",
        "file": "data/1611.01353.pdf"
    },
    {
        "title": "Leveraging Importance Weights in Subset Selection",
        "url": "http://arxiv.org/abs/2301.12052v1",
        "authors": [
            "Gui Citovsky",
            "Giulia DeSalvo",
            "Sanjiv Kumar",
            "Srikumar Ramalingam",
            "Afshin Rostamizadeh",
            "Yunjuan Wang"
        ],
        "abstract": "We present a subset selection algorithm designed to work with arbitrary model families in a practical batch setting. In such a setting, an algorithm can sample examples one at a time but, in order to limit overhead costs, is only able to update its state (i.e. further train model weights) once a large enough batch of examples is selected. Our algorithm, IWeS, selects examples by importance sampling where the sampling probability assigned to each example is based on the entropy of models trained on previously selected batches. IWeS admits significant performance improvement compared to other subset selection algorithms for seven publicly available datasets. Additionally, it is competitive in an active learning setting, where the label information is not available at selection time. We also provide an initial theoretical analysis to support our importance weighting approach, proving generalization and sampling rate bounds.",
        "file": "data/2301.12052.pdf"
    },
    {
        "title": "Learnable Privacy-Preserving Anonymization for Pedestrian Images",
        "url": "http://arxiv.org/abs/2207.11677v1",
        "authors": [
            "Junwu Zhang",
            "Mang Ye",
            "Yao Yang"
        ],
        "abstract": "This paper studies a novel privacy-preserving anonymization problem for pedestrian images, which preserves personal identity information (PII) for authorized models and prevents PII from being recognized by third parties. Conventional anonymization methods unavoidably cause semantic information loss, leading to limited data utility. Besides, existing learned anonymization techniques, while retaining various identity-irrelevant utilities, will change the pedestrian identity, and thus are unsuitable for training robust re-identification models. To explore the privacy-utility trade-off for pedestrian images, we propose a joint learning reversible anonymization framework, which can reversibly generate full-body anonymous images with little performance drop on person re-identification tasks. The core idea is that we adopt desensitized images generated by conventional methods as the initial privacy-preserving supervision and jointly train an anonymization encoder with a recovery decoder and an identity-invariant model. We further propose a progressive training strategy to improve the performance, which iteratively upgrades the initial anonymization supervision. Experiments further demonstrate the effectiveness of our anonymized pedestrian images for privacy protection, which boosts the re-identification performance while preserving privacy. Code is available at \\url{https://github.com/whuzjw/privacy-reid}.",
        "file": "data/557_an_information_theoretic_analy.pdf"
    },
    {
        "title": "Structure Learning in Graphical Modeling",
        "url": "http://arxiv.org/abs/1606.02359v1",
        "authors": [
            "Mathias Drton",
            "Marloes H. Maathuis"
        ],
        "abstract": "A graphical model is a statistical model that is associated to a graph whose nodes correspond to variables of interest. The edges of the graph reflect allowed conditional dependencies among the variables. Graphical models admit computationally convenient factorization properties and have long been a valuable tool for tractable modeling of multivariate distributions. More recently, applications such as reconstructing gene regulatory networks from gene expression data have driven major advances in structure learning, that is, estimating the graph underlying a model. We review some of these advances and discuss methods such as the graphical lasso and neighborhood selection for undirected graphical models (or Markov random fields), and the PC algorithm and score-based search methods for directed graphical models (or Bayesian networks). We further review extensions that account for effects of latent variables and heterogeneous data sources.",
        "file": "data/1606.02359.pdf"
    },
    {
        "title": "Improving Self-Supervised Learning by Characterizing Idealized Representations",
        "url": "http://arxiv.org/abs/2209.06235v2",
        "authors": [
            "Yann Dubois",
            "Tatsunori Hashimoto",
            "Stefano Ermon",
            "Percy Liang"
        ],
        "abstract": "Despite the empirical successes of self-supervised learning (SSL) methods, it is unclear what characteristics of their representations lead to high downstream accuracies. In this work, we characterize properties that SSL representations should ideally satisfy. Specifically, we prove necessary and sufficient conditions such that for any task invariant to given data augmentations, desired probes (e.g., linear or MLP) trained on that representation attain perfect accuracy. These requirements lead to a unifying conceptual framework for improving existing SSL methods and deriving new ones. For contrastive learning, our framework prescribes simple but significant improvements to previous methods such as using asymmetric projection heads. For non-contrastive learning, we use our framework to derive a simple and novel objective. Our resulting SSL algorithms outperform baselines on standard benchmarks, including SwAV+multicrops on linear probing of ImageNet.",
        "file": "data/2209.06235.pdf"
    },
    {
        "title": "Unpacking Information Bottlenecks: Unifying Information-Theoretic Objectives in Deep Learning",
        "url": "http://arxiv.org/abs/2003.12537v3",
        "authors": [
            "Andreas Kirsch",
            "Clare Lyle",
            "Yarin Gal"
        ],
        "abstract": "The Information Bottleneck principle offers both a mechanism to explain how deep neural networks train and generalize, as well as a regularized objective with which to train models. However, multiple competing objectives are proposed in the literature, and the information-theoretic quantities used in these objectives are difficult to compute for large deep neural networks, which in turn limits their use as a training objective. In this work, we review these quantities and compare and unify previously proposed objectives, which allows us to develop surrogate objectives more friendly to optimization without relying on cumbersome tools such as density estimation. We find that these surrogate objectives allow us to apply the information bottleneck to modern neural network architectures. We demonstrate our insights on MNIST, CIFAR-10 and Imagenette with modern DNN architectures (ResNets).",
        "file": "data/2003.12537.pdf"
    },
    {
        "title": "Extracting Training Data from Diffusion Models",
        "url": "http://arxiv.org/abs/2301.13188v1",
        "authors": [
            "Nicholas Carlini",
            "Jamie Hayes",
            "Milad Nasr",
            "Matthew Jagielski",
            "Vikash Sehwag",
            "Florian Tram\u00e8r",
            "Borja Balle",
            "Daphne Ippolito",
            "Eric Wallace"
        ],
        "abstract": "Image diffusion models such as DALL-E 2, Imagen, and Stable Diffusion have attracted significant attention due to their ability to generate high-quality synthetic images. In this work, we show that diffusion models memorize individual images from their training data and emit them at generation time. With a generate-and-filter pipeline, we extract over a thousand training examples from state-of-the-art models, ranging from photographs of individual people to trademarked company logos. We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.",
        "file": "data/2301.13188.pdf"
    },
    {
        "title": "ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders",
        "url": "http://arxiv.org/abs/2301.00808v1",
        "authors": [
            "Sanghyun Woo",
            "Shoubhik Debnath",
            "Ronghang Hu",
            "Xinlei Chen",
            "Zhuang Liu",
            "In So Kweon",
            "Saining Xie"
        ],
        "abstract": "Driven by improved architectures and better representation learning frameworks, the field of visual recognition has enjoyed rapid modernization and performance boost in the early 2020s. For example, modern ConvNets, represented by ConvNeXt, have demonstrated strong performance in various scenarios. While these models were originally designed for supervised learning with ImageNet labels, they can also potentially benefit from self-supervised learning techniques such as masked autoencoders (MAE). However, we found that simply combining these two approaches leads to subpar performance. In this paper, we propose a fully convolutional masked autoencoder framework and a new Global Response Normalization (GRN) layer that can be added to the ConvNeXt architecture to enhance inter-channel feature competition. This co-design of self-supervised learning techniques and architectural improvement results in a new model family called ConvNeXt V2, which significantly improves the performance of pure ConvNets on various recognition benchmarks, including ImageNet classification, COCO detection, and ADE20K segmentation. We also provide pre-trained ConvNeXt V2 models of various sizes, ranging from an efficient 3.7M-parameter Atto model with 76.7% top-1 accuracy on ImageNet, to a 650M Huge model that achieves a state-of-the-art 88.9% accuracy using only public training data.",
        "file": "data/2301.00808.pdf"
    }
]